# Setup y EjecuciÃ³n

GuÃ­a para ejecutar el proyecto **offline (para tesis)** y opcionalmente **en AWS (para producciÃ³n)**.

---

## ğŸŸ¢ FASE 1: EJECUCIÃ“N OFFLINE (Tesis Local)

### Requisitos

Necesitas solo **Python 3.9 o superior**:

```bash
python3 --version    # Verifica que sea >= 3.9
```

### InstalaciÃ³n de Dependencias

```bash
# En la raÃ­z del proyecto
pip install -r requirements.txt
```

**Dependencias principales:**
- pandas - ManipulaciÃ³n de datos
- numpy - CÃ¡lculos numÃ©ricos
- scikit-learn - Modelos ML
- xgboost - Boosting (opcional)
- joblib - SerializaciÃ³n

### Ejecutar el Entrenamiento

```bash
# En la raÃ­z del proyecto
python3 ejecutar-evaluacion-algoritmos.py
```

### Salida Esperada

El script generarÃ¡ **2 archivos**:

```
models/
â”œâ”€â”€ mejor_modelo.pkl              â† Modelo entrenado (pickle)
â””â”€â”€ metrics_resultados.csv        â† Tabla de mÃ©tricas

Consola:
â”œâ”€ === 1) Carga y limpieza ===
â”œâ”€ Registros tras limpieza: XXXX
â”œâ”€ === 2) ConstrucciÃ³n de pares ===
â”œâ”€ Casos (pares) construidos: XXXX
â”œâ”€ === 3) Features y split estratificado ===
â”œâ”€ === 4) Entrenamiento y evaluaciÃ³n ===
â”œâ”€ [MÃ©tricas de cada modelo...]
â”œâ”€ Mejor modelo: [random_forest|xgboost|logistic_regression] (F1=X.XXXX)
â”œâ”€ === 5) Uplift de negocio ===
â”œâ”€ Tasa baseline: X.XXXX
â”œâ”€ Tasa con modelo: X.XXXX
â””â”€ Uplift: XX.XXX%
```

### VerificaciÃ³n

Verifica que se crearon los archivos:

```bash
ls -lh models/mejor_modelo.pkl
cat metrics_resultados.csv
```

**Â¡Listo!** Ya tienes el modelo entrenado y listo para usar.

---

## ğŸ“š AnÃ¡lisis de Resultados

Los resultados del entrenamiento se encuentran en:

### 1. `models/mejor_modelo.pkl`
Archivo serializado con el modelo entrenado. Contiene:
- Preprocesador (StandardScaler + OneHotEncoder)
- Clasificador entrenado (Random Forest, XGBoost o Logistic Regression)

**Uso:**
```python
import joblib
modelo = joblib.load('models/mejor_modelo.pkl')
predicciones = modelo.predict_proba(X_test)
```

### 2. `metrics_resultados.csv`
Tabla comparativa de los 3 modelos:

```
modelo,threshold,accuracy,precision,recall,f1,auc_roc
random_forest,0.3,0.7234,0.6543,0.7891,0.7185,0.7856
xgboost,0.4,0.7145,0.6234,0.7654,0.6923,0.7623
logistic_regression,0.5,0.6987,0.5876,0.7234,0.6521,0.7234
```

### 3. Consola (Uplift de Negocio)
El script calcula automÃ¡ticamente:
```
Tasa baseline (reintentar todo):   65.0%
Tasa con modelo (top 70%):         72.5%
Uplift (puntos porcentuales):      7.5%
```

---

## ğŸ”¬ Usar el Modelo Entrenado

### OpciÃ³n A: En Python Local

```python
import joblib
import pandas as pd

# Cargar modelo
modelo = joblib.load('models/mejor_modelo.pkl')

# Preparar datos
evento = pd.DataFrame({
    'monto': [150.0],
    'delta_horas': [5.0],
    'retry_hour': [10],
    'retry_dayofweek': [2],
    'retry_is_weekend': [0],
    'error_categoria': ['cliente_4xx'],
    'detalle_fail': ['Saldo insuficiente'],
    'retry_hora_bucket': ['manana']
})

# PredicciÃ³n
probabilidad = modelo.predict_proba(evento)[:, 1][0]
decision = 'Reintentar' if probabilidad >= 0.3 else 'No reintentar'

print(f"Probabilidad de Ã©xito: {probabilidad:.2%}")
print(f"DecisiÃ³n: {decision}")
```

### OpciÃ³n B: En Jupyter Notebook

Ver archivo: `notebooks/exploracion.ipynb`

```bash
jupyter notebook notebooks/exploracion.ipynb
```

---

## ğŸ”´ FASE 2: DESPLIEGUE EN AWS (Opcional)

### âš ï¸ Importante
**AWS es completamente opcional**. Solo si quieres desplegar el modelo en producciÃ³n con inferencia en tiempo real.

---

### Requisitos para AWS

- Node.js >= 18.x
- npm >= 9.x
- AWS CLI v2 (configurado con credenciales)
- Docker (instalado y corriendo)

### Verificar Requisitos

```bash
node --version          # >= v18.x
npm --version           # >= 9.x
aws --version           # v2
aws sts get-caller-identity  # Verifica credenciales
docker --version        # Verifica Docker corriendo
```

---

### Setup de AWS

#### 1. Navegar a la carpeta AWS

```bash
cd aws
```

#### 2. Instalar Dependencias Node.js

```bash
npm install
```

#### 3. Compilar TypeScript

```bash
npm run build
```

#### 4. Validar SÃ­ntesis de CDK

```bash
npx cdk synth
```

---

### Deployment AutomÃ¡tico

**Se recomienda usar el script automÃ¡tico:**

```bash
# Desde la carpeta aws/
bash scripts/setup-and-deploy.sh
```

Este script:
1. Verifica todos los requisitos
2. Instala dependencias
3. Compila el cÃ³digo
4. Valida la sÃ­ntesis
5. Despliega en AWS
6. Sube el modelo a S3

**Tiempo estimado:** 15-20 minutos

---

### Deployment Manual (Alternativa)

Si prefieres hacerlo paso a paso:

```bash
# 1. AsegÃºrate de que mejor_modelo.pkl existe
ls ../models/mejor_modelo.pkl

# 2. Desplegar stack
npx cdk deploy

# 3. Obtener nombre del bucket
BUCKET=$(aws cloudformation describe-stacks \
  --stack-name ml-retries-stack \
  --query 'Stacks[0].Outputs[?OutputKey==`ModelBucketName`].OutputValue' \
  --output text)

# 4. Subir modelo a S3
aws s3 cp ../models/mejor_modelo.pkl s3://${BUCKET}/models/mejor_modelo.pkl
```

---

### Testing de AWS

Una vez desplegado:

```bash
# Test Lambda directa
bash scripts/test-lambda.sh

# Test State Machine (batch)
bash scripts/test-state-machine.sh
```

---

### Ver Logs

```bash
aws logs tail /aws/lambda/ml-retries-inference --follow
```

---

### Destruir Infraestructura

Cuando ya no necesites AWS:

```bash
# Desde la carpeta aws/
bash scripts/destroy.sh
```

El script automÃ¡ticamente:
- âœ“ Muestra advertencia crÃ­tica
- âœ“ Requiere confirmaciÃ³n manual
- âœ“ Elimina CloudFormation stack completo
- âœ“ Espera a que termine la eliminaciÃ³n

---

## ğŸ“‚ Estructura Final

DespuÃ©s de ejecutar todo:

```
dpa-tesis-2025-2/
â”‚
â”œâ”€â”€ README.md                              â† DescripciÃ³n proyecto
â”œâ”€â”€ SETUP_Y_EJECUCION.md                   â† Este archivo
â”œâ”€â”€ requirements.txt                       â† Dependencias Python
â”‚
â”œâ”€â”€ ejecutar-evaluacion-algoritmos.py      â† Script principal
â”œâ”€â”€ suscripciones.xlsx                     â† Datos de entrada
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mejor_modelo.pkl                   â† Generado âœ“
â”‚   â””â”€â”€ metrics_resultados.csv             â† Generado âœ“
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploracion.ipynb                  â† AnÃ¡lisis
â”‚
â””â”€â”€ aws/                                   â† OPCIONAL
    â”œâ”€â”€ README_AWS.md
    â”œâ”€â”€ QUICKSTART_AWS.md
    â”œâ”€â”€ bin/
    â”œâ”€â”€ lib/
    â”œâ”€â”€ lambda/
    â”œâ”€â”€ scripts/
    â”œâ”€â”€ docs/
    â””â”€â”€ package.json
```

---

## âœ… Checklist de EjecuciÃ³n

### Fase Offline (Tesis)
- [ ] Verificar Python 3.9+
- [ ] Instalar dependencias: `pip install -r requirements.txt`
- [ ] Ejecutar: `python3 ejecutar-evaluacion-algoritmos.py`
- [ ] Verificar salida: `models/mejor_modelo.pkl`
- [ ] Revisar mÃ©tricas: `metrics_resultados.csv`

### Fase AWS (ProducciÃ³n)
- [ ] Verificar requisitos (Node, npm, AWS CLI, Docker)
- [ ] Entrar a carpeta: `cd aws`
- [ ] Instalar deps: `npm install`
- [ ] Desplegar: `bash scripts/setup-and-deploy.sh`
- [ ] Testear: `bash scripts/test-lambda.sh`
- [ ] Ver logs: `aws logs tail /aws/lambda/ml-retries-inference --follow`

---

## ğŸ†˜ Troubleshooting

### Error: "No module named pandas"

```bash
pip install -r requirements.txt
```

### Error: "suscripciones.xlsx not found"

AsegÃºrate de estar en la raÃ­z del proyecto:
```bash
ls suscripciones.xlsx
```

### Error: "mejor_modelo.pkl not found" (AWS)

El archivo debe estar en `models/`:
```bash
ls models/mejor_modelo.pkl
```

### Error: AWS CLI no configurado

```bash
aws configure
aws sts get-caller-identity
```

### Error: Docker no estÃ¡ corriendo

Inicia Docker:
```bash
docker ps  # Verifica que funciona
```

### Error: Node/npm no encontrado

Instala desde: https://nodejs.org/

---

## ğŸ“– DocumentaciÃ³n Completa

Para mÃ¡s detalles, ver:

- **Fase Offline (Tesis):** Ver `README.md`
- **Fase AWS (ProducciÃ³n):** Ver `aws/README_AWS.md` y `aws/QUICKSTART_AWS.md`
- **AnÃ¡lisis TÃ©cnico:** Ver `aws/docs/`

---

## ğŸ¯ Resumen RÃ¡pido

### Solo Tesis (Local)
```bash
pip install -r requirements.txt
python3 ejecutar-evaluacion-algoritmos.py
# â†’ Genera: models/mejor_modelo.pkl + metrics_resultados.csv
```

### Con AWS (ProducciÃ³n)
```bash
pip install -r requirements.txt
python3 ejecutar-evaluacion-algoritmos.py
cd aws
bash scripts/setup-and-deploy.sh
# â†’ Despliega en AWS + sube modelo a S3
bash scripts/test-lambda.sh
bash scripts/test-state-machine.sh
```

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
